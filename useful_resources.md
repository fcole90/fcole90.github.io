---
layout: page
title: Resources and Study Material
description: A list of of resources that I found useful and/or interesting to read.
published: true
---

### [Introduction to Probability and Statistics](https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/)

Introductory course on Probability and Statistics. Very usefull to both who are approaching the subject for the first time as well as for those feeling the need for a brush up. It includes counting, probabilities, joint probabilities, probability distributions, frequentist approach to statistics, Bayesian approach to statistics. Many parts of the content of this course are fundamental in the context of machine learning.

![Bayesian updating with conjugate normal distributions. (Image by Jerry Orloff and Jonathan Bloom.)](https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/18-05s14.jpg)


### [Andrew Ng - Machine Learning Course](https://www.youtube.com/watch?v=PPLop4L2eGk&list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN)

Introductory course on all about machine learning by [Andrew Ng](https://en.wikipedia.org/wiki/Andrew_Ng). This course provides a solid background on the most important concepts related to machine learning, and as such is highly suggested as an introductory course to machine learning.

![Andrew NG giving a lecture](https://i.ytimg.com/vi/PPLop4L2eGk/hqdefault.jpg?sqp=-oaymwEXCNACELwBSFryq4qpAwkIARUAAIhCGAE=&rs=AOn4CLBc4QH5ahgQ5w_n6gF9HWtLaIxztQ)


### [Deep Learning Book](http://www.deeplearningbook.org) 

*Verbatim:* The Deep Learning textbook is a resource intended to help students and practitioners enter the field of machine learning in general and deep learning in particular. The online version of the book is now complete and will remain available online for free.

![Deep Learning book cover](https://images-na.ssl-images-amazon.com/images/I/61fim5QqaqL.jpg)



### [CS231n Convolutional Neural Networks for Visual Recognition](https://cs231n.github.io/) [Video Lectures](https://www.youtube.com/watch?v=vT1JzLTH4G4&list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk)

Stanford introductory course on Neural Networks in general and on Convolutional Neural Networks for Image Recognition in particular. It even includes lectures on Variational Autoencoders (VAE) in the lecture on [Generative Models](https://www.youtube.com/watch?v=5WoItGTWV54&index=13&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv). I highly suggest this course because it has a gradual learning curve but it provides a good amount of relevant theory and details, as well as showing how to put such information into application.


### [Hugo Larochelle Restricted Boltzmann Machines](https://www.youtube.com/watch?v=p4Vh_zMw-HQ&list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH&index=36)

Video lectures by Hugo Larochelle about Restricted Boltzmann Machines.


### [Visual Information Theory](http://colah.github.io/posts/2015-09-Visual-Information/)

This article explains in a clear and concise way how to understand and visualise probabilities
and other information theory data. It is also very useful to understand the cross-entropy function.


### [Reinventing explanations](http://michaelnielsen.org/reinventing_explanation/)

An approach on how to think about science, including an example application on the Simpson's paradox.


